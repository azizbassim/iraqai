import json
import random
import os
import requests
from flask import Flask, request, jsonify, render_template
from dotenv import load_dotenv

# Load environment variables
load_dotenv()
API_TOKEN = os.getenv("API_TOKEN")  # âœ… Token hidden here

app = Flask(__name__, template_folder='.')

# ========== Your existing local model ==========
try:
    with open('iraq_ai_model_v2.json', 'r', encoding='utf-8') as f:
        model_data = json.load(f)
    knowledge_base = model_data['knowledge_base']
except:
    knowledge_base = {
        'Ù…Ø±Ø­Ø¨Ø§': 'greeting',
        'Ø¹Ø±Ø§Ù‚': 'location',
        'Ù†Ù…ÙˆØ°Ø¬': 'ai',
        'Ø´ÙƒØ±Ø§Ù‹': 'thanks'
    }

responses = {
    'greeting': ['Ù…Ø±Ø­Ø¨Ø§! ÙƒÙŠÙ Ø­Ø§Ù„ÙƒØŸ', 'Ø£Ù‡Ù„Ø§ ÙˆØ³Ù‡Ù„Ø§!', 'Ø³Ø¹ÙŠØ¯ Ø¨Ù„Ù‚Ø§Ø¦Ùƒ!'],
    'location': ['Ø§Ù„Ø¹Ø±Ø§Ù‚ Ø¨Ù„Ø¯ Ø¬Ù…ÙŠÙ„', 'Ø¨ØºØ¯Ø§Ø¯ Ø¹Ø§ØµÙ…Ø© Ø§Ù„Ø¹Ø±Ø§Ù‚', 'Ø§Ù„Ø¬ØºØ±Ø§ÙÙŠØ§ Ø§Ù„Ø¹Ø±Ø§Ù‚ÙŠØ© ØºÙ†ÙŠØ©'],
    'question': ['Ù‡Ø°Ø§ Ø³Ø¤Ø§Ù„ Ø°ÙƒÙŠ!', 'Ø£Ø³ØªØ·ÙŠØ¹ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ', 'Ø¯Ø¹Ù†ÙŠ Ø£ÙÙƒØ±'],
    'thanks': ['Ù…Ù† Ø¯ÙˆØ§Ø¹ÙŠ Ø³Ø±ÙˆØ±ÙŠ!', 'Ø´ÙƒØ±Ø§Ù‹ Ù„Ùƒ!', 'ÙŠØ³Ø¹Ø¯Ù†ÙŠ Ø®Ø¯Ù…ØªÙƒ'],
    'ai': ['Ù†Ø¹Ù…ØŒ Ø£Ù†Ø§ Ù†Ù…ÙˆØ°Ø¬ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ', 'ØªÙ… ØªØ·ÙˆÙŠØ±ÙŠ Ù„Ù„Ø¹Ø±Ø§Ù‚', 'Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ'],
    'unknown': ['Ø£Ø¹ØªØ°Ø±ØŒ Ù„Ù… Ø£ÙÙ‡Ù… Ø¬ÙŠØ¯Ø§Ù‹', 'Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØµÙŠØ§ØºØ©ØŸ', 'Ù„Ø§ Ø£Ù…Ù„Ùƒ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ù‡Ø°Ø§']
}

def local_chat(user_input):
    words = user_input.split()
    matches = {}
    
    for word in words:
        if word in knowledge_base:
            category = knowledge_base[word]
            matches[category] = matches.get(category, 0) + 1
    
    category = max(matches, key=matches.get) if matches else 'unknown'
    response = random.choice(responses.get(category, responses['unknown']))
    
    return response, category

# ========== Web Routes ==========

@app.route('/')
def home():
    return render_template('index.html')  # Serves your HTML

# ========== API Route (Token stays hidden!) ==========

@app.route('/api/chat', methods=['POST'])
def api_chat():
    user_message = request.json.get('message')
    
    # Call external LLM API with hidden token
    # Change this URL based on your LLM provider
    response = requests.post(
        'https://api.openai.com/v1/chat/completions',  # or your LLM URL
        headers={
            'Authorization': f'Bearer {API_TOKEN}',  # âœ… Secure!
            'Content-Type': 'application/json'
        },
        json={
            'model': 'gpt-4',
            'messages': [{'role': 'user', 'content': user_message}]
        }
    )
    
    return jsonify(response.json())

# ========== Run Server ==========

if __name__ == '__main__':
    print("=" * 70)
    print("ğŸ‡®ğŸ‡¶ IRAQ AI CHATBOT - Server Running")
    print("=" * 70)
    print("\nOpen http://localhost:5000 in your browser\n")
    app.run(debug=True, port=5000)
